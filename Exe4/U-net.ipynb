{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.23529889469\n",
      "0.240527334747\n",
      "100\n",
      "0.701697364725\n",
      "0.979551305627\n",
      "200\n",
      "0.711174224266\n",
      "0.953967908226\n",
      "300\n",
      "0.896903522924\n",
      "0.9943678672\n",
      "400\n",
      "0.908082994378\n",
      "0.923934801258\n",
      "500\n",
      "0.935092692002\n",
      "0.933889048577\n",
      "600\n",
      "0.938608690526\n",
      "0.950568964268\n",
      "700\n",
      "0.935316101806\n",
      "0.858178554167\n",
      "800\n",
      "0.932507135336\n",
      "0.961802011955\n",
      "900\n",
      "0.948799228026\n",
      "0.965096750639\n",
      "1000\n",
      "0.95136800699\n",
      "0.995698924731\n",
      "1100\n",
      "0.851934892467\n",
      "0.988179669031\n",
      "1200\n",
      "0.953730295439\n",
      "0.93974340493\n",
      "1300\n",
      "0.955980051104\n",
      "0.986858619417\n",
      "1400\n",
      "0.957053803028\n",
      "0.98057109214\n",
      "1500\n",
      "0.957009804086\n",
      "1.0\n",
      "1600\n",
      "0.943872586307\n",
      "0.849494880077\n",
      "1700\n",
      "0.957486010158\n",
      "0.970997509887\n",
      "1800\n",
      "0.957665815079\n",
      "0.975047702921\n",
      "1900\n",
      "0.955054718181\n",
      "0.943385326401\n",
      "2000\n",
      "0.953297258123\n",
      "0.9036570701\n",
      "2100\n",
      "0.96041926973\n",
      "0.963949500109\n",
      "2200\n",
      "0.950035913179\n",
      "0.975917767988\n",
      "2300\n",
      "0.965657632886\n",
      "0.953400595195\n",
      "2400\n",
      "0.965231067512\n",
      "0.978387120488\n",
      "2500\n",
      "0.96338615199\n",
      "0.977224303872\n",
      "2600\n",
      "0.952572236762\n",
      "0.967107667568\n",
      "2700\n",
      "0.965296140752\n",
      "0.97867803838\n",
      "2800\n",
      "0.961838610318\n",
      "0.963089940915\n",
      "2900\n",
      "0.955862737263\n",
      "0.774495582223\n",
      "3000\n",
      "0.958025111031\n",
      "0.931252242555\n",
      "3100\n",
      "0.959842101867\n",
      "0.897081629776\n",
      "3200\n",
      "0.954711790575\n",
      "0.991268960414\n",
      "3300\n",
      "0.962473200787\n",
      "0.933611151027\n",
      "3400\n",
      "0.963998214158\n",
      "0.984221779842\n",
      "3500\n",
      "0.968184919755\n",
      "0.964953271028\n",
      "3600\n",
      "0.963351368563\n",
      "0.899491812535\n",
      "3700\n",
      "0.9649146297\n",
      "0.920228326793\n",
      "3800\n",
      "0.956520558739\n",
      "0.98057109214\n",
      "3900\n",
      "0.965022387166\n",
      "0.967826849956\n",
      "4000\n",
      "0.967807683615\n",
      "0.938765218644\n",
      "4100\n",
      "0.962999379214\n",
      "0.984660766962\n",
      "4200\n",
      "0.966452273235\n",
      "0.996143005489\n",
      "4300\n",
      "0.966156881861\n",
      "0.976788599971\n",
      "4400\n",
      "0.964293063191\n",
      "0.972731271075\n",
      "4500\n",
      "0.967067769911\n",
      "0.99244836011\n",
      "4600\n",
      "0.965517779941\n",
      "0.969266793502\n",
      "4700\n",
      "0.966367843854\n",
      "0.97345457212\n",
      "4800\n",
      "0.968478948034\n",
      "0.996883579432\n",
      "4900\n",
      "0.952176931284\n",
      "0.998960112902\n",
      "5000\n",
      "0.959278104739\n",
      "0.994072317724\n",
      "5100\n",
      "0.968758899417\n",
      "0.974323233805\n",
      "5200\n",
      "0.957436841392\n",
      "0.979696925114\n",
      "5300\n",
      "0.969909743206\n",
      "0.98275989096\n",
      "5400\n",
      "0.964487347529\n",
      "0.98744553578\n",
      "5500\n",
      "0.965879631712\n",
      "0.99836637707\n",
      "5600\n",
      "0.964333808879\n",
      "0.995846929694\n",
      "5700\n",
      "0.961176911818\n",
      "0.995994956612\n",
      "5800\n",
      "0.963995444552\n",
      "0.979551305627\n",
      "5900\n",
      "0.970089429685\n",
      "0.997179962894\n",
      "6000\n",
      "0.966424240423\n",
      "0.920639451898\n",
      "6100\n",
      "0.962188038382\n",
      "0.974178403756\n",
      "6200\n",
      "0.967477719577\n",
      "0.938485918029\n",
      "6300\n",
      "0.959682852631\n",
      "0.988473474213\n",
      "6400\n",
      "0.965934742814\n",
      "0.931252242555\n",
      "6500\n",
      "0.968937344269\n",
      "0.98057109214\n",
      "6600\n",
      "0.962331152198\n",
      "1.0\n",
      "6700\n",
      "0.964205305083\n",
      "0.964379562044\n",
      "6800\n",
      "0.968050095461\n",
      "0.987739124012\n",
      "6900\n",
      "0.967568242764\n",
      "0.987005316007\n",
      "7000\n",
      "0.969124189821\n",
      "0.976353088052\n",
      "7100\n",
      "0.97081598602\n",
      "0.987885950657\n",
      "7200\n",
      "0.963725462075\n",
      "0.988326560768\n",
      "7300\n",
      "0.96348636711\n",
      "0.995698924731\n",
      "7400\n",
      "0.961641918126\n",
      "0.993924575832\n",
      "7500\n",
      "0.966897511367\n",
      "1.0\n",
      "7600\n",
      "0.968933254425\n",
      "0.989208367211\n",
      "7700\n",
      "0.963648130907\n",
      "0.997179962894\n",
      "7800\n",
      "0.969072668433\n",
      "0.990385326529\n",
      "7900\n",
      "0.969613926755\n",
      "0.98480713917\n",
      "8000\n",
      "0.968961747813\n",
      "0.983490566038\n",
      "8100\n",
      "0.960613638175\n",
      "0.98744553578\n",
      "8200\n",
      "0.971049445292\n",
      "0.982321744255\n",
      "8300\n",
      "0.969748941813\n",
      "0.984221779842\n",
      "8400\n",
      "0.969882890928\n",
      "0.977514879859\n",
      "8500\n",
      "0.961862326321\n",
      "0.976933813267\n",
      "8600\n",
      "0.968029700976\n",
      "0.991268960414\n",
      "8700\n",
      "0.967358800695\n",
      "0.989061345159\n",
      "8800\n",
      "0.965532128303\n",
      "0.970276008493\n",
      "8900\n",
      "0.969982305243\n",
      "0.985539324185\n",
      "9000\n",
      "0.971387182455\n",
      "0.992890995261\n",
      "9100\n",
      "0.974179739884\n",
      "0.979405707561\n",
      "9200\n",
      "0.969157647299\n",
      "1.0\n",
      "9300\n",
      "0.963788446751\n",
      "0.986858619417\n",
      "9400\n",
      "0.972235541153\n",
      "0.988179669031\n",
      "9500\n",
      "0.961427956889\n",
      "0.974902766566\n",
      "9600\n",
      "0.969624536438\n",
      "0.99747643435\n",
      "9700\n",
      "0.968265245049\n",
      "0.953967908226\n",
      "9800\n",
      "0.969516529486\n",
      "0.976788599971\n",
      "9900\n",
      "0.971494741683\n",
      "0.999257113142\n",
      "10000\n",
      "0.965649747256\n",
      "0.998069641399\n",
      "10100\n",
      "0.966522783344\n",
      "0.996439169139\n",
      "10200\n",
      "0.96305170643\n",
      "0.998217998218\n",
      "10300\n",
      "0.968020560319\n",
      "0.98480713917\n",
      "10400\n",
      "0.965270195086\n",
      "0.97533763946\n",
      "10500\n",
      "0.96929090922\n",
      "0.977224303872\n",
      "10600\n",
      "0.962588605451\n",
      "0.97345457212\n",
      "10700\n",
      "0.966916786252\n",
      "0.96452295788\n",
      "10800\n",
      "0.962948408223\n",
      "0.994515674794\n",
      "10900\n",
      "0.964204982122\n",
      "0.99836637707\n",
      "11000\n",
      "0.968342835196\n",
      "0.985978894547\n",
      "11100\n",
      "0.956412892466\n",
      "0.988032798995\n",
      "11200\n",
      "0.970149816032\n",
      "0.988473474213\n",
      "11300\n",
      "0.969401668744\n",
      "0.994072317724\n",
      "11400\n",
      "0.97213590207\n",
      "0.984660766962\n",
      "11500\n",
      "0.971428930846\n",
      "0.990679784008\n",
      "11600\n",
      "0.969544790452\n",
      "0.998514777959\n",
      "11700\n",
      "0.96875514091\n",
      "0.997624703088\n",
      "11800\n",
      "0.968358326803\n",
      "0.992595883311\n",
      "11900\n",
      "0.967542472998\n",
      "0.991121633619\n",
      "12000\n",
      "0.965867857748\n",
      "0.972297544888\n",
      "12100\n",
      "0.969810073551\n",
      "0.988326560768\n",
      "12200\n",
      "0.973057086419\n",
      "0.956951716114\n",
      "12300\n",
      "0.966978856647\n",
      "0.99747643435\n",
      "12400\n",
      "0.966613299269\n",
      "0.996143005489\n",
      "12500\n",
      "0.965033681835\n",
      "0.999554201649\n",
      "12600\n",
      "0.970094026949\n",
      "0.997031760166\n",
      "12700\n",
      "0.967751458387\n",
      "0.985685826016\n",
      "12800\n",
      "0.970646486762\n",
      "0.984368087303\n",
      "12900\n",
      "0.971723974811\n",
      "0.981154299176\n",
      "13000\n",
      "0.965896915559\n",
      "0.995107124324\n",
      "13100\n",
      "0.964803854267\n",
      "0.9943678672\n",
      "13200\n",
      "0.968560071437\n",
      "0.977950904013\n",
      "13300\n",
      "0.968049934549\n",
      "0.998514777959\n",
      "13400\n",
      "0.969811446771\n",
      "0.988473474213\n",
      "13500\n",
      "0.970628858557\n",
      "0.993481481481\n",
      "13600\n",
      "0.968111587403\n",
      "0.994220081512\n",
      "13700\n",
      "0.972119399079\n",
      "0.996587283923\n",
      "13800\n",
      "0.962815885694\n",
      "0.960087399854\n",
      "13900\n",
      "0.970338123821\n",
      "1.0\n",
      "14000\n",
      "0.968770479517\n",
      "0.975772703913\n",
      "14100\n",
      "0.964343727849\n",
      "0.985685826016\n",
      "14200\n",
      "0.970940111856\n",
      "0.98862040937\n",
      "14300\n",
      "0.969849108711\n",
      "0.98744553578\n",
      "14400\n",
      "0.968267509432\n",
      "0.991858485678\n",
      "14500\n",
      "0.969728847605\n",
      "0.989796672828\n",
      "14600\n",
      "0.972658504882\n",
      "0.986418659581\n",
      "14700\n",
      "0.97064325792\n",
      "0.998960112902\n",
      "14800\n",
      "0.969343654619\n",
      "0.996735420686\n",
      "14900\n",
      "0.967700148918\n",
      "0.990090956149\n",
      "15000\n",
      "0.966381138037\n",
      "0.994959229059\n",
      "15100\n",
      "0.962329889713\n",
      "0.989796672828\n",
      "15200\n",
      "0.969059947328\n",
      "0.960944331099\n",
      "15300\n",
      "0.966609298506\n",
      "0.992595883311\n",
      "15400\n",
      "0.970441494074\n",
      "0.988179669031\n",
      "15500\n",
      "0.970964446698\n",
      "1.0\n",
      "15600\n",
      "0.969117752173\n",
      "0.983198231393\n",
      "15700\n",
      "0.970970071258\n",
      "0.998663200891\n",
      "15800\n",
      "0.969295618925\n",
      "0.99156367942\n",
      "15900\n",
      "0.966941741166\n",
      "0.988473474213\n",
      "16000\n",
      "0.969522859028\n",
      "0.990974328623\n",
      "16100\n",
      "0.970454620224\n",
      "0.99377685583\n",
      "16200\n",
      "0.96682921105\n",
      "0.997624703088\n",
      "16300\n",
      "0.972729870489\n",
      "0.99881164587\n",
      "16400\n",
      "0.969779947741\n",
      "0.995698924731\n",
      "16500\n",
      "0.96561057222\n",
      "0.994959229059\n",
      "16600\n",
      "0.972662594911\n",
      "0.993924575832\n",
      "16700\n",
      "0.968314510685\n",
      "0.990090956149\n",
      "16800\n",
      "0.965443679986\n",
      "0.993333827124\n",
      "16900\n",
      "0.96721821903\n",
      "0.981446031512\n",
      "17000\n",
      "0.967878323997\n",
      "0.994959229059\n",
      "17100\n",
      "0.965958164182\n",
      "0.984514416341\n",
      "17200\n",
      "0.966810986491\n",
      "0.982029754014\n",
      "17300\n",
      "0.969156388912\n",
      "0.99244836011\n",
      "17400\n",
      "0.966610472123\n",
      "0.99747643435\n",
      "17500\n",
      "0.964223375052\n",
      "0.995255041518\n",
      "17600\n",
      "0.962128841993\n",
      "0.988914344838\n",
      "17700\n",
      "0.968642531141\n",
      "0.988032798995\n",
      "17800\n",
      "0.966481783147\n",
      "0.990679784008\n",
      "17900\n",
      "0.970572547165\n",
      "1.0\n",
      "18000\n",
      "0.973089317516\n",
      "0.975627661136\n",
      "18100\n",
      "0.970094244457\n",
      "0.997328187621\n",
      "18200\n",
      "0.968891454238\n",
      "0.982175738381\n",
      "18300\n",
      "0.966347667816\n",
      "0.999554201649\n",
      "18400\n",
      "0.968156087502\n",
      "0.997921306607\n",
      "18500\n",
      "0.969693921134\n",
      "0.985246385364\n",
      "18600\n",
      "0.963247425435\n",
      "0.967107667568\n",
      "18700\n",
      "0.970765357696\n",
      "0.989943803608\n",
      "18800\n",
      "0.968052670065\n",
      "0.999108601991\n",
      "18900\n",
      "0.972168154169\n",
      "0.991121633619\n",
      "19000\n",
      "0.971278509585\n",
      "0.980279617366\n",
      "19100\n",
      "0.967250130469\n",
      "0.987885950657\n",
      "19200\n",
      "0.973015374314\n",
      "0.99244836011\n",
      "19300\n",
      "0.972612518197\n",
      "0.997772993839\n",
      "19400\n",
      "0.971103657768\n",
      "0.999554201649\n",
      "19500\n",
      "0.967917088255\n",
      "0.978387120488\n",
      "19600\n",
      "0.966911692513\n",
      "0.990827045421\n",
      "19700\n",
      "0.970328626699\n",
      "0.989649563803\n",
      "19800\n",
      "0.971550262235\n",
      "1.0\n",
      "19900\n",
      "0.97245370081\n",
      "0.995402980648\n",
      "20000\n",
      "0.972013975705\n",
      "0.992595883311\n",
      "20100\n",
      "0.971948372514\n",
      "0.995107124324\n",
      "20200\n",
      "0.974475083237\n",
      "0.987005316007\n",
      "20300\n",
      "0.968416756374\n",
      "0.994663504299\n",
      "20400\n",
      "0.970504502807\n",
      "0.99200592154\n",
      "20500\n",
      "0.970480947206\n",
      "0.991416309013\n",
      "20600\n",
      "0.96892916662\n",
      "0.994663504299\n",
      "20700\n",
      "0.973395773157\n",
      "1.0\n",
      "20800\n",
      "0.966187735242\n",
      "0.987592319055\n",
      "20900\n",
      "0.971127332657\n",
      "0.99940564636\n",
      "21000\n",
      "0.973345937537\n",
      "0.993629157715\n",
      "21100\n",
      "0.969719556366\n",
      "0.99747643435\n",
      "21200\n",
      "0.971314993713\n",
      "0.98480713917\n",
      "21300\n",
      "0.971149405044\n",
      "0.997921306607\n",
      "21400\n",
      "0.970891984576\n",
      "0.989061345159\n",
      "21500\n",
      "0.973093735135\n",
      "0.993038584018\n",
      "21600\n",
      "0.972714407665\n",
      "0.99377685583\n",
      "21700\n",
      "0.965530213737\n",
      "0.984075493955\n",
      "21800\n",
      "0.969837214038\n",
      "0.973744041071\n",
      "21900\n",
      "0.971915676636\n",
      "0.990827045421\n",
      "22000\n",
      "0.97416185126\n",
      "0.99156367942\n",
      "22100\n",
      "0.968981397591\n",
      "0.990679784008\n",
      "22200\n",
      "0.969065699621\n",
      "0.994515674794\n",
      "22300\n",
      "0.970852953129\n",
      "0.993186194638\n",
      "22400\n",
      "0.970056392062\n",
      "0.988179669031\n",
      "22500\n",
      "0.970369012191\n",
      "0.998960112902\n",
      "22600\n",
      "0.97105442135\n",
      "0.994515674794\n",
      "22700\n",
      "0.970839185641\n",
      "0.980425344028\n",
      "22800\n",
      "0.966662288367\n",
      "0.998069641399\n",
      "22900\n",
      "0.967907670479\n",
      "0.995846929694\n",
      "23000\n",
      "0.968582364645\n",
      "0.988767366243\n",
      "23100\n",
      "0.966615768618\n",
      "0.990090956149\n",
      "23200\n",
      "0.971584339632\n",
      "0.99171107164\n",
      "23300\n",
      "0.966065985298\n",
      "0.987885950657\n",
      "23400\n",
      "0.966047342361\n",
      "0.988914344838\n",
      "23500\n",
      "0.971920869555\n",
      "0.990238130454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23600\n",
      "0.968502040511\n",
      "0.996883579432\n",
      "23700\n",
      "0.969738750041\n",
      "0.98744553578\n",
      "23800\n",
      "0.969396710218\n",
      "0.994515674794\n",
      "23900\n",
      "0.972698617366\n",
      "0.997179962894\n",
      "24000\n",
      "0.970236302387\n",
      "0.994811355719\n",
      "24100\n",
      "0.973020440104\n",
      "0.989208367211\n",
      "24200\n",
      "0.967208995561\n",
      "0.993333827124\n",
      "24300\n",
      "0.973371768018\n",
      "0.983198231393\n",
      "24400\n",
      "0.970511949256\n",
      "0.992595883311\n",
      "24500\n",
      "0.969186973879\n",
      "0.994220081512\n",
      "24600\n",
      "0.969922966791\n",
      "0.993038584018\n",
      "24700\n",
      "0.968911593479\n",
      "0.987739124012\n",
      "24800\n",
      "0.973944078366\n",
      "0.995402980648\n",
      "24900\n",
      "0.969452094259\n",
      "0.99200592154\n",
      "25000\n",
      "0.973473973053\n",
      "0.994959229059\n",
      "25100\n",
      "0.972086364152\n",
      "0.99274342836\n",
      "25200\n",
      "0.972358593175\n",
      "0.989649563803\n",
      "25300\n",
      "0.972185468415\n",
      "0.99230085875\n",
      "25400\n",
      "0.97196671709\n",
      "0.996735420686\n",
      "25500\n",
      "0.971997760698\n",
      "0.994811355719\n",
      "25600\n",
      "0.97153261512\n",
      "0.991858485678\n",
      "25700\n",
      "0.970931674889\n",
      "0.991858485678\n",
      "25800\n",
      "0.963752564005\n",
      "0.995698924731\n",
      "25900\n",
      "0.96968171311\n",
      "0.992153379229\n",
      "26000\n",
      "0.968877953734\n",
      "0.992890995261\n",
      "26100\n",
      "0.968798326933\n",
      "0.991858485678\n",
      "26200\n",
      "0.97023362515\n",
      "1.0\n",
      "26300\n",
      "0.966458901654\n",
      "0.989208367211\n",
      "26400\n",
      "0.968728537424\n",
      "0.997624703088\n",
      "26500\n",
      "0.970442991913\n",
      "1.0\n",
      "26600\n",
      "0.970959385008\n",
      "0.995846929694\n",
      "26700\n",
      "0.970163838386\n",
      "0.994220081512\n",
      "26800\n",
      "0.971758633902\n",
      "0.995846929694\n",
      "26900\n",
      "0.968240384715\n",
      "0.995550941717\n",
      "27000\n",
      "0.965753368341\n",
      "0.99747643435\n",
      "27100\n",
      "0.969923831756\n",
      "0.988326560768\n",
      "27200\n",
      "0.965738424974\n",
      "0.973020527859\n",
      "27300\n",
      "0.969007562516\n",
      "1.0\n",
      "27400\n",
      "0.968714973726\n",
      "0.998069641399\n",
      "27500\n",
      "0.968420896952\n",
      "0.991121633619\n",
      "27600\n",
      "0.969431679056\n",
      "0.982321744255\n",
      "27700\n",
      "0.972219271185\n",
      "0.999702779016\n",
      "27800\n",
      "0.966361076475\n",
      "0.993333827124\n",
      "27900\n",
      "0.971039688876\n",
      "0.993038584018\n",
      "28000\n",
      "0.971313631543\n",
      "0.996439169139\n",
      "28100\n",
      "0.970719316091\n",
      "0.9943678672\n",
      "28200\n",
      "0.971012635626\n",
      "0.99377685583\n",
      "28300\n",
      "0.968831799396\n",
      "0.996735420686\n",
      "28400\n",
      "0.972432470316\n",
      "0.99377685583\n",
      "28500\n",
      "0.973331431907\n",
      "0.987592319055\n",
      "28600\n",
      "0.966747220666\n",
      "0.995846929694\n",
      "28700\n",
      "0.971853593105\n",
      "0.993629157715\n",
      "28800\n",
      "0.968598812014\n",
      "0.995698924731\n",
      "28900\n",
      "0.970951824287\n",
      "0.990385326529\n",
      "29000\n",
      "0.973423339313\n",
      "0.996735420686\n",
      "29100\n",
      "0.974346643153\n",
      "0.99377685583\n",
      "29200\n",
      "0.969867092532\n",
      "0.982175738381\n",
      "29300\n",
      "0.970851323482\n",
      "1.0\n",
      "29400\n",
      "0.972477016141\n",
      "0.994515674794\n",
      "29500\n",
      "0.968950163751\n",
      "0.998069641399\n",
      "29600\n",
      "0.968165392255\n",
      "0.991416309013\n",
      "29700\n",
      "0.972114374169\n",
      "0.99377685583\n",
      "29800\n",
      "0.971963015317\n",
      "0.999108601991\n",
      "29900\n",
      "0.969895987302\n",
      "0.995994956612\n",
      "30000\n",
      "0.968267900409\n",
      "0.995255041518\n",
      "30100\n",
      "0.968632070654\n",
      "0.995846929694\n",
      "30200\n",
      "0.971457681196\n",
      "0.99230085875\n",
      "30300\n",
      "0.971146433676\n",
      "0.99940564636\n",
      "30400\n",
      "0.967546099639\n",
      "0.998217998218\n",
      "30500\n",
      "0.967015613511\n",
      "0.994220081512\n",
      "30600\n",
      "0.966086743438\n",
      "0.988032798995\n",
      "30700\n",
      "0.971589289655\n",
      "0.99940564636\n",
      "30800\n",
      "0.967779702675\n",
      "0.999108601991\n",
      "30900\n",
      "0.969940603906\n",
      "0.995402980648\n",
      "31000\n",
      "0.967869888584\n",
      "0.994515674794\n",
      "31100\n",
      "0.96712571485\n",
      "0.997031760166\n",
      "31200\n",
      "0.972731979117\n",
      "0.990385326529\n",
      "31300\n",
      "0.971267575745\n",
      "0.998069641399\n",
      "31400\n",
      "0.968714161502\n",
      "0.99244836011\n",
      "31500\n",
      "0.970055013451\n",
      "0.993924575832\n",
      "31600\n",
      "0.967801478122\n",
      "0.997772993839\n",
      "31700\n",
      "0.968192019336\n",
      "0.983636765681\n",
      "31800\n",
      "0.969805853583\n",
      "0.996587283923\n",
      "31900\n",
      "0.967989438409\n",
      "0.997772993839\n",
      "32000\n",
      "0.968107383123\n",
      "1.0\n",
      "32100\n",
      "0.969799039844\n",
      "0.9943678672\n",
      "32200\n",
      "0.970401857404\n",
      "0.994811355719\n",
      "32300\n",
      "0.968638072845\n",
      "0.996143005489\n",
      "32400\n",
      "0.970771476147\n",
      "0.997179962894\n",
      "32500\n",
      "0.970723953425\n",
      "0.997328187621\n",
      "32600\n",
      "0.968517389781\n",
      "0.97998822837\n",
      "32700\n",
      "0.969411359045\n",
      "0.993333827124\n",
      "32800\n",
      "0.969737134622\n",
      "0.999257113142\n",
      "32900\n",
      "0.968255645253\n",
      "0.991268960414\n",
      "33000\n",
      "0.970713775129\n",
      "0.986125461255\n",
      "33100\n",
      "0.969561488485\n",
      "1.0\n",
      "33200\n",
      "0.969197340323\n",
      "1.0\n",
      "33300\n",
      "0.970413494802\n",
      "0.997328187621\n",
      "33400\n",
      "0.970779986162\n",
      "0.974612957664\n",
      "33500\n",
      "0.967239861917\n",
      "0.985099948366\n",
      "33600\n",
      "0.972218923807\n",
      "0.993333827124\n",
      "33700\n",
      "0.963841188404\n",
      "0.987298774184\n",
      "33800\n",
      "0.971351651908\n",
      "0.997624703088\n",
      "33900\n",
      "0.969459248249\n",
      "0.994072317724\n",
      "34000\n",
      "0.97094640053\n",
      "0.99156367942\n",
      "34100\n",
      "0.967831066744\n",
      "0.994220081512\n",
      "34200\n",
      "0.973732410651\n",
      "0.998663200891\n",
      "34300\n",
      "0.973524499196\n",
      "0.991858485678\n",
      "34400\n",
      "0.971410411284\n",
      "0.994959229059\n",
      "34500\n",
      "0.970530217444\n",
      "0.998217998218\n",
      "34600\n",
      "0.970034025409\n",
      "0.99836637707\n",
      "34700\n",
      "0.968021965293\n",
      "0.994072317724\n",
      "34800\n",
      "0.971164174061\n",
      "0.99230085875\n",
      "34900\n",
      "0.972127761732\n",
      "0.999257113142\n",
      "35000\n",
      "0.971434599605\n",
      "0.994072317724\n",
      "35100\n",
      "0.968351837632\n",
      "0.993333827124\n",
      "35200\n",
      "0.968960521476\n",
      "0.989943803608\n",
      "35300\n",
      "0.972221343587\n",
      "0.991416309013\n",
      "35400\n",
      "0.970252453752\n",
      "1.0\n",
      "35500\n",
      "0.968285072064\n",
      "1.0\n",
      "35600\n",
      "0.972336776703\n",
      "0.998217998218\n",
      "35700\n",
      "0.972839326131\n",
      "0.998514777959\n",
      "35800\n",
      "0.972933201444\n",
      "1.0\n",
      "35900\n",
      "0.972990774375\n",
      "0.9943678672\n",
      "36000\n",
      "0.970415030756\n",
      "0.989943803608\n",
      "36100\n",
      "0.972352304645\n",
      "0.985539324185\n",
      "36200\n",
      "0.971913119044\n",
      "0.99230085875\n",
      "36300\n",
      "0.970840064992\n",
      "0.993333827124\n",
      "36400\n",
      "0.975282284995\n",
      "0.991858485678\n",
      "36500\n",
      "0.972971123677\n",
      "0.997179962894\n",
      "36600\n",
      "0.97157473575\n",
      "0.998217998218\n",
      "36700\n",
      "0.969629541328\n",
      "0.99244836011\n",
      "36800\n",
      "0.969137502425\n",
      "0.984368087303\n",
      "36900\n",
      "0.969113898824\n",
      "0.99940564636\n",
      "37000\n",
      "0.97091520861\n",
      "0.989355410999\n",
      "37100\n",
      "0.969168409154\n",
      "0.994072317724\n",
      "37200\n",
      "0.968565961726\n",
      "0.991121633619\n",
      "37300\n",
      "0.970866128164\n",
      "0.998514777959\n",
      "37400\n",
      "0.970986969704\n",
      "0.999851378465\n",
      "37500\n",
      "0.9708042648\n",
      "0.996735420686\n",
      "37600\n",
      "0.966540589086\n",
      "0.99156367942\n",
      "37700\n",
      "0.968920615619\n",
      "0.999108601991\n",
      "37800\n",
      "0.971501042338\n",
      "0.994811355719\n",
      "37900\n",
      "0.967503528338\n",
      "0.997921306607\n",
      "38000\n",
      "0.969282517687\n",
      "0.993038584018\n",
      "38100\n",
      "0.970299203285\n",
      "0.987005316007\n",
      "38200\n",
      "0.972799457149\n",
      "0.997624703088\n",
      "38300\n",
      "0.971476716514\n",
      "0.996439169139\n",
      "38400\n",
      "0.972849313753\n",
      "0.999851378465\n",
      "38500\n",
      "0.968980713954\n",
      "0.999257113142\n",
      "38600\n",
      "0.970276055547\n",
      "0.994811355719\n",
      "38700\n",
      "0.969890067755\n",
      "1.0\n",
      "38800\n",
      "0.969501868797\n",
      "0.98480713917\n",
      "38900\n",
      "0.970692656999\n",
      "0.987298774184\n",
      "39000\n",
      "0.971286084538\n",
      "0.998217998218\n",
      "39100\n",
      "0.969874492412\n",
      "0.993333827124\n",
      "39200\n",
      "0.972331809506\n",
      "0.994663504299\n",
      "39300\n",
      "0.973337439444\n",
      "0.996143005489\n",
      "39400\n",
      "0.971997132613\n",
      "0.989796672828\n",
      "39500\n",
      "0.972229773303\n",
      "0.999702779016\n",
      "39600\n",
      "0.972507739898\n",
      "0.999257113142\n",
      "39700\n",
      "0.971535708939\n",
      "0.99836637707\n",
      "39800\n",
      "0.97250452692\n",
      "0.9943678672\n",
      "39900\n",
      "0.974202059427\n",
      "0.997328187621\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Format \"jpg\" is not supported.\nSupported formats: eps, pdf, pgf, png, ps, raw, rgba, svg, svgz.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-41e0b271c83c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Negative logarithm of accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0mfig5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'plot.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shutdown -s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, **kwargs)\u001b[0m\n\u001b[1;32m   1812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m         \u001b[0;31m# get canvas object and print method for format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2162\u001b[0;31m         \u001b[0mcanvas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_canvas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2163\u001b[0m         \u001b[0mprint_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'print_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_output_canvas\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         raise ValueError('Format \"%s\" is not supported.\\n'\n\u001b[1;32m   2104\u001b[0m                          \u001b[0;34m'Supported formats: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m                          '%s.' % (format, ', '.join(formats)))\n\u001b[0m\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m     def print_figure(self, filename, dpi=None, facecolor=None, edgecolor=None,\n",
      "\u001b[0;31mValueError\u001b[0m: Format \"jpg\" is not supported.\nSupported formats: eps, pdf, pgf, png, ps, raw, rgba, svg, svgz."
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        with h5py.File(\"cell_data.h5\", \"r\") as data:\n",
    "            self.train_images = [data[\"/train_image_{}\".format(i)][:] for i in range(28)]\n",
    "            self.train_labels = [data[\"/train_label_{}\".format(i)][:] for i in range(28)]\n",
    "            self.test_images = [data[\"/test_image_{}\".format(i)][:] for i in range(3)]\n",
    "            self.test_labels = [data[\"/test_label_{}\".format(i)][:] for i in range(3)]\n",
    "    \n",
    "        self.input_resolution = 300\n",
    "        self.label_resolution = 116\n",
    "\n",
    "        self.offset = (300 - 116) // 2\n",
    "\n",
    "        image = np.empty([300, 300, 1])\n",
    "        label = np.empty([116, 116])\n",
    "\n",
    "    def get_train_image_list_and_label_list(self):\n",
    "        n = random.randint(0, len(self.train_images) - 1)\n",
    "        x = random.randint(0, (self.train_images[n].shape)[1] - self.input_resolution - 1)\n",
    "        y = random.randint(0, (self.train_images[n].shape)[0] - self.input_resolution - 1)\n",
    "        image = self.train_images[n][y:y + self.input_resolution, x:x + self.input_resolution, :]\n",
    "\n",
    "        x += self.offset\n",
    "        y += self.offset\n",
    "        label = self.train_labels[n][y:y + self.label_resolution, x:x + self.label_resolution]\n",
    "    \n",
    "        return [image], [label]\n",
    "\n",
    "    def get_test_image_list_and_label_list(self):\n",
    "        coord_list = [[0,0], [0, 300], [218, 0], [218, 300]]\n",
    "    \n",
    "        image_list = []\n",
    "        label_list = []\n",
    "    \n",
    "        for image_id in range(3):\n",
    "            for y, x in coord_list:\n",
    "                image = self.test_images[image_id][y:y + self.input_resolution, x:x + self.input_resolution, :]\n",
    "                image_list.append(image)\n",
    "                x += self.offset\n",
    "                y += self.offset\n",
    "                label = self.test_labels[image_id][y:y + self.label_resolution, x:x + self.label_resolution]\n",
    "                label_list.append(label)\n",
    "    \n",
    "\n",
    "        return image_list, label_list\n",
    "\n",
    "def weight_variable(shape,i):\n",
    "    initial = tf.glorot_uniform_initializer()\n",
    "    return tf.get_variable('a_{}'.format(i),initializer=initial,shape = shape)\n",
    "\n",
    "def bias_variable(shape,i):\n",
    "    initial = tf.zeros_initializer()\n",
    "    return tf.get_variable('a_{}'.format(i), initializer=initial, shape=shape)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 300, 300, 1])\n",
    "y = tf.placeholder(tf.int32, [None, 116, 116])\n",
    "\n",
    "# data class init\n",
    "data = Data()\n",
    "# train data init\n",
    "image,label = data.get_train_image_list_and_label_list()\n",
    "\n",
    "\n",
    "def network(x):\n",
    "    i = 0\n",
    "    # Weights for first convolution\n",
    "    i += 1\n",
    "    W_conv1 = weight_variable([3, 3, 1, 32],i)\n",
    "    i += 1\n",
    "    b_conv1 = bias_variable([32],i)\n",
    "    # First convolution output size: 298x298x32\n",
    "    h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "    # Weight for second convultion\n",
    "    i += 1\n",
    "    W_conv2 = weight_variable([3, 3, 32, 32],i)\n",
    "    i += 1\n",
    "    b_conv2 = bias_variable([32],i)\n",
    "    # Second convolution output size: 296x296x32\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "    # First pooling with filter 2x2 output size: 148x148x32\n",
    "    h_pool1 = max_pool_2x2(h_conv2)\n",
    "    # Weight for third convolution\n",
    "    i += 1\n",
    "    W_conv3 = weight_variable([3, 3, 32, 64],i)\n",
    "    i += 1\n",
    "    b_conv3 = bias_variable([64],i)\n",
    "    # Third convolution output size: 146x146x64\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool1, W_conv3) + b_conv3)\n",
    "    # Weight for fourth convolution\n",
    "    i += 1\n",
    "    W_conv4 = weight_variable([3, 3, 64, 64],i)\n",
    "    i += 1\n",
    "    b_conv4 = bias_variable([64],i)\n",
    "    # Fourth convolution output size 144x144x64\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4) + b_conv4)\n",
    "    # Second pooling outpuz size: 72x72x64\n",
    "    h_pool2 = max_pool_2x2(h_conv4)\n",
    "    # Weights for fifth convolution\n",
    "    i += 1\n",
    "    W_conv5 = weight_variable([3, 3, 64, 128],i)\n",
    "    i += 1\n",
    "    b_conv5 = bias_variable([128],i)\n",
    "    # Fifth convolution output size: 70x70x128\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_pool2, W_conv5) + b_conv5)\n",
    "    # Weights for sixth convolution\n",
    "    i += 1\n",
    "    W_conv6 = weight_variable([3, 3, 128, 128],i)\n",
    "    i += 1\n",
    "    b_conv6 = bias_variable([128],i)\n",
    "    # Sixth convolution output size : 68x68x128\n",
    "    h_conv6 = tf.nn.relu(conv2d(h_conv5, W_conv6) + b_conv6)\n",
    "    # Third pooling output size : 34x34x128\n",
    "    h_pool3 = max_pool_2x2(h_conv6)\n",
    "    # Weights for seventh convolution\n",
    "    i += 1\n",
    "    W_conv7 = weight_variable([3, 3, 128, 256],i)\n",
    "    i += 1\n",
    "    b_conv7 = bias_variable([256],i)\n",
    "    # Seventh convolution output size: 32x32x256\n",
    "    h_conv7 = tf.nn.relu(conv2d(h_pool3, W_conv7) + b_conv7)\n",
    "    # Weight for eight convolution\n",
    "    i += 1\n",
    "    W_conv8 = weight_variable([3, 3, 256, 256],i)\n",
    "    i += 1\n",
    "    b_conv8 = bias_variable([256],i)\n",
    "    # Eight convolution output size : 30x30x256\n",
    "    h_conv8 = tf.nn.relu(conv2d(h_conv7, W_conv8) + b_conv8)\n",
    "    # Forth pooling output size : 15x15x256\n",
    "    h_pool4 = max_pool_2x2(h_conv8)\n",
    "    # Weights for ninth convolution\n",
    "    i += 1\n",
    "    W_conv9 = weight_variable([3, 3, 256, 512],i)\n",
    "    i += 1\n",
    "    b_conv9 = bias_variable([512],i)\n",
    "    # Ninth convolution output size : 13x13x512\n",
    "    h_conv9 = tf.nn.relu(conv2d(h_pool4, W_conv9) + b_conv9)\n",
    "    # Weights for tenth convolution\n",
    "    i += 1\n",
    "    W_conv10 = weight_variable([3, 3, 512, 512],i)\n",
    "    i += 1\n",
    "    b_conv10 = bias_variable([512],i)\n",
    "    # Tenth convolution output size : 11x11x512\n",
    "    h_conv10 = tf.nn.relu(conv2d(h_conv9, W_conv10) + b_conv10)\n",
    "    # cropping of data\n",
    "    # Croppped size: 120x120x32\n",
    "    h_conv2_cropped = tf.image.resize_image_with_crop_or_pad(h_conv2,120,120)\n",
    "    # Cropped size: 64x64x64\n",
    "    h_conv4_cropped = tf.image.resize_image_with_crop_or_pad(h_conv4,64,64)\n",
    "    # Cropped size: 36x36x128\n",
    "    h_conv6_cropped = tf.image.resize_image_with_crop_or_pad(h_conv6,36,36)\n",
    "    # Cropped size: 22x22x256\n",
    "    h_conv8_cropped = tf.image.resize_image_with_crop_or_pad(h_conv8,22,22)\n",
    "    # Output shape for deconvolution\n",
    "    out_shape1 = [1, 22, 22, 256]\n",
    "    # Stride size 2x2\n",
    "    stride  = [1, 2, 2, 1]\n",
    "    # Weight for deconvolution\n",
    "    i += 1\n",
    "    dw_conv1 = weight_variable([2, 2, 256, 512],i)\n",
    "    # First deconvolution output shape: 22x22x256\n",
    "    t_conv1 = tf.nn.conv2d_transpose(h_conv10,dw_conv1,out_shape1,stride, padding='SAME', data_format = 'NHWC')\n",
    "    # First concatenation\n",
    "    t_conv1_con = tf.concat([h_conv8_cropped,t_conv1],3)\n",
    "    # Weightf for elevent convolution\n",
    "    i += 1\n",
    "    W_conv11 = weight_variable([3, 3, 512, 256],i)\n",
    "    i += 1\n",
    "    b_conv11 = bias_variable([256],i)\n",
    "    # Eleventh convolution output shape: 20x20x256\n",
    "    h_conv11 = tf.nn.relu(conv2d(t_conv1_con, W_conv11) + b_conv11)\n",
    "    # Weights for twelve convolution\n",
    "    i += 1\n",
    "    W_conv12 = weight_variable([3, 3, 256, 256],i)\n",
    "    i += 1\n",
    "    b_conv12 = bias_variable([256],i)\n",
    "    # Twevleth convolution output shape : 18x18x256\n",
    "    h_conv12 = tf.nn.relu(conv2d(h_conv11, W_conv12) + b_conv12)\n",
    "    # Output shape for second deconvolution\n",
    "    out_shape2 = [1, 36, 36, 128]\n",
    "    # Weights for deconvolution\n",
    "    i += 1\n",
    "    dw_conv2 = weight_variable([2, 2, 128, 256],i)\n",
    "    # Second deconvolution output shape:36x36x128\n",
    "    t_conv2 = tf.nn.conv2d_transpose(h_conv12,dw_conv2,out_shape2,stride, padding='SAME', data_format = 'NHWC')\n",
    "    # Second concatenation\n",
    "    t_conv2_con = tf.concat([h_conv6_cropped,t_conv2],3)\n",
    "    # Weights for thirteenth convolution\n",
    "    i += 1\n",
    "    W_conv13 = weight_variable([3, 3, 256, 128],i)\n",
    "    i += 1\n",
    "    b_conv13 = bias_variable([128],i)\n",
    "    # Thirteenth convolution output shape:34x34x128\n",
    "    h_conv13 = tf.nn.relu(conv2d(t_conv2_con, W_conv13) + b_conv13)\n",
    "    #Weights for fourteenth convolution\n",
    "    i += 1\n",
    "    W_conv14 = weight_variable([3, 3, 128, 128],i)\n",
    "    i += 1\n",
    "    b_conv14 = bias_variable([128],i)\n",
    "    # Fourteenth convolution output shape: 32x32x128\n",
    "    h_conv14 = tf.nn.relu(conv2d(h_conv13, W_conv14) + b_conv14)\n",
    "    #Weights for deconvolution\n",
    "    i += 1\n",
    "    dw_conv3 = weight_variable([2, 2, 64, 128],i)\n",
    "    # output shape 3\n",
    "    out_shape3 = [1, 64, 64, 64]\n",
    "    # Third deconvolution\n",
    "    t_conv3 = tf.nn.conv2d_transpose(h_conv14,dw_conv3,out_shape3,stride, padding='SAME', data_format = 'NHWC')\n",
    "    # Third concatenation\n",
    "    t_conv3_con = tf.concat([h_conv4_cropped,t_conv3],3)\n",
    "    # Weights for fifteenth convolution\n",
    "    i += 1\n",
    "    W_conv15 = weight_variable([3, 3, 128, 64],i)\n",
    "    i += 1\n",
    "    b_conv15 = bias_variable([64],i)\n",
    "    # Fifteenth convolution output shape: 62x62x64\n",
    "    h_conv15 = tf.nn.relu(conv2d(t_conv3_con, W_conv15) + b_conv15)\n",
    "    # Weights for sixteents convolution\n",
    "    i += 1\n",
    "    W_conv16 = weight_variable([3, 3, 64, 64],i)\n",
    "    i += 1\n",
    "    b_conv16 = bias_variable([64],i)\n",
    "    # Sixteents convolution output shape: 60x60x64\n",
    "    h_conv16 = tf.nn.relu(conv2d(h_conv15, W_conv16) + b_conv16)\n",
    "    # Weights for fourth deconvolution\n",
    "    i += 1\n",
    "    dw_conv4 = weight_variable([2, 2, 32, 64],i)\n",
    "    # output shape 4\n",
    "    out_shape4 = [1, 120, 120, 32]\n",
    "    # Fourth deconvolution\n",
    "    t_conv4 = tf.nn.conv2d_transpose(h_conv16,dw_conv4,out_shape4,stride, padding='SAME', data_format = 'NHWC')\n",
    "    # Fourth concatanation\n",
    "    t_conv4_con = tf.concat([h_conv2_cropped,t_conv4],3)\n",
    "    # Weights for seventeenth convolution\n",
    "    i += 1\n",
    "    W_conv17 = weight_variable([3, 3, 64, 32],i)\n",
    "    i += 1\n",
    "    b_conv17 = bias_variable([32],i)\n",
    "    # Seventeenth convolution output shape: 118x118x32\n",
    "    h_conv17 = tf.nn.relu(conv2d(t_conv4_con, W_conv17) + b_conv17)\n",
    "    # Weights for eighteenth convolution\n",
    "    i += 1\n",
    "    W_conv18 = weight_variable([3, 3, 32, 32],i)\n",
    "    i += 1\n",
    "    b_conv18 = bias_variable([32],i)\n",
    "    # Eighteents convolution output shape: 116x116x32\n",
    "    h_conv18 = tf.nn.relu(conv2d(h_conv17, W_conv18) + b_conv18)\n",
    "    # Output convolution weights\n",
    "    i += 1\n",
    "    W_conv19 = weight_variable([1, 1, 32, 2],i)\n",
    "    i += 1\n",
    "    b_conv19 = bias_variable([2],i)\n",
    "    # Output convolution with softmax outputshape 116x116x2\n",
    "    h_conv19 = conv2d(h_conv18, W_conv19) + b_conv19\n",
    "    return h_conv19\n",
    "\n",
    "y_new = network(x)\n",
    "\n",
    "loss_vector = []\n",
    "\n",
    "# loss function\n",
    "mini_batch_size = 1\n",
    "learning_rate = 0.0001\n",
    "y_r = tf.reshape(y, [mini_batch_size * 116 * 116])\n",
    "y_h = tf.one_hot(y_r, 2)\n",
    "y_new_reshape = tf.reshape(y_new,[1*116*116, 2])\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=y_new_reshape,labels=y_h)\n",
    "loss = tf.reduce_mean(loss)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate, 0.95, 0.99).minimize(loss)\n",
    "\n",
    "\n",
    "c_predict = tf.equal(tf.argmax(y_new_reshape, 1), tf.argmax(y_h, 1))\n",
    "c_predict = tf.cast(c_predict, tf.float32)\n",
    "\n",
    "loss_train_array = []\n",
    "accuracy_train_array = []\n",
    "loss_val_array = []\n",
    "accuracy_val_array = []\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss_vector = []\n",
    "    loss_vector_val = []\n",
    "    for i in range(40000):\n",
    "        # train process\n",
    "        image, label = data.get_train_image_list_and_label_list()\n",
    "        sess.run(train_step, feed_dict={x: image, y: label})\n",
    "        if i % 100 == 0:\n",
    "            rand = random.randint(0,12)\n",
    "            # train prediction\n",
    "            pred = c_predict.eval(feed_dict={x:image, y:label})\n",
    "            train_acc = (np.sum(pred))/(2*pred.shape[0]-np.sum(pred))\n",
    "            loss_value = loss.eval(feed_dict={x: image, y: label})\n",
    "            loss_train_array.append(loss_value)\n",
    "            accuracy_train_array.append(train_acc)\n",
    "            # test process\n",
    "            test_acc = 0\n",
    "            image_list, label_list = data.get_test_image_list_and_label_list()\n",
    "            for j in range(len(label_list)):\n",
    "\n",
    "                if j == rand and i % 1000 == 0 or (j== rand and i == 39999):\n",
    "                    output = y_new.eval(feed_dict={x: np.reshape(image_list[j], [1, 300, 300, 1]),\n",
    "                                                   y: np.reshape(label_list[j], [1, 116, 116])})\n",
    "                    output = np.argmax(output, axis=-1)\n",
    "                    pic = np.reshape(output,[116,116])\n",
    "                    fig1 = plt.figure(1)\n",
    "                    plt.imshow(pic, cmap ='gray')\n",
    "                    fig1.savefig('Prediction' + str(j)+ 'Iteration:' + str(i))\n",
    "                    pic1 = np.reshape(label_list[j],[116,116])\n",
    "                    fig2 = plt.figure(2)\n",
    "                    plt.imshow(pic1, cmap = 'gray')\n",
    "                    fig2.savefig('Label' + str(j) + 'Iteration:' + str(i))\n",
    "                t_predict = c_predict.eval(feed_dict={x: np.reshape(image_list[j],[1,300,300,1]),y:np.reshape(label_list[j],[1,116,116])})\n",
    "                test_acc += (np.sum(t_predict)/(2*t_predict.shape[0] - np.sum(t_predict)))\n",
    "            test_acc /= len(label_list)\n",
    "            print(i)\n",
    "            print(test_acc)\n",
    "            print(train_acc)\n",
    "            accuracy_val_array.append(test_acc)\n",
    "    epochs = range(len(accuracy_train_array))\n",
    "    fig5 = plt.figure()\n",
    "    plt.plot(epochs,accuracy_train_array)\n",
    "    plt.plot(epochs, accuracy_val_array)\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend(['Train accuracy','Validation accuracy'],loc = 'upper left')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Negative logarithm of accuracy')\n",
    "    fig5.savefig('plot.jpg')\n",
    "os.system('shutdown -s')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
